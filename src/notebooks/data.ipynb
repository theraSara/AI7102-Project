{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(67349) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (2.2.6)\n",
      "Requirement already satisfied: matplotlib in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (3.9.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (1.7.2)\n",
      "Requirement already satisfied: torch in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: tqdm in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (4.66.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: filelock in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/vanilla/.pyenv/versions/3.11.9/envs/venv/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy matplotlib scikit-learn torch torchvision torchaudio tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torchaudio\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 10039\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"/Users/vanilla/.cache/kagglehub/datasets/samuelsamsudinng/iemocap-emotion-speech-database/versions/1\"\n",
    "df = pd.read_csv(f\"{dataset_path}/iemocap_full_dataset.csv\")\n",
    "\n",
    "print(f\"Original dataset size: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['session', 'method', 'gender', 'emotion', 'n_annotators', 'agreement',\n",
       "       'path'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "xxx    2507\n",
       "fru    1849\n",
       "neu    1708\n",
       "ang    1103\n",
       "sad    1084\n",
       "exc    1041\n",
       "hap     595\n",
       "sur     107\n",
       "fea      40\n",
       "oth       3\n",
       "dis       2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset size:  7380\n",
      "Filtered emotion distribution:  emotion\n",
      "fru    1849\n",
      "neu    1708\n",
      "ang    1103\n",
      "sad    1084\n",
      "exc    1041\n",
      "hap     595\n",
      "Name: count, dtype: int64\n",
      "Removed 2659 utterances (xxx, sur, fea, oth, dis)\n"
     ]
    }
   ],
   "source": [
    "target_emotions = ['hap', 'sad', 'ang', 'neu', 'fru', 'exc']\n",
    "\n",
    "df_filtered = df[df['emotion'].isin(target_emotions)].copy()\n",
    "\n",
    "print(\"Filtered dataset size: \", len(df_filtered))\n",
    "print(\"Filtered emotion distribution: \", df_filtered['emotion'].value_counts())\n",
    "print(f\"Removed {len(df) - len(df_filtered)} utterances (xxx, sur, fea, oth, dis)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling class imbalance by merging excited class (1041) with happy (595)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts before merging:  emotion\n",
      "fru    1849\n",
      "neu    1708\n",
      "ang    1103\n",
      "sad    1084\n",
      "exc    1041\n",
      "hap     595\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_counts = df_filtered['emotion'].value_counts()\n",
    "print(\"Class counts before merging: \", class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts after merging exc -> hap:  emotion\n",
      "fru    1849\n",
      "neu    1708\n",
      "hap    1636\n",
      "ang    1103\n",
      "sad    1084\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_filtered_merge = df_filtered.copy()\n",
    "df_filtered_merge['emotion'] = df_filtered_merge['emotion'].replace({'exc': 'hap'})\n",
    "class_counts_after = df_filtered_merge['emotion'].value_counts()\n",
    "print(\"Class counts after merging exc -> hap: \", class_counts_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking imabalnce ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalance ratio: 1.71\n"
     ]
    }
   ],
   "source": [
    "imbalance_ratio = class_counts_after.max() / class_counts_after.min()\n",
    "print(f\"Imbalance ratio: {imbalance_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Train/Val/Test Splits (Session-Based)\n",
    "\n",
    "Train: Sessions 1-4 (90% Train, 10% Val)\n",
    "\n",
    "Test: Session 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df = df_filtered_merge[df_filtered_merge['session'].isin([1, 2, 3, 4])].copy()\n",
    "test_df = df_filtered_merge[df_filtered_merge['session'] == 5].copy()\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    train_val_df,\n",
    "    test_size = 0.1,\n",
    "    stratify=train_val_df['emotion'],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Summary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>Samples</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>5182</td>\n",
       "      <td>70.216802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Validation</td>\n",
       "      <td>576</td>\n",
       "      <td>7.804878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test</td>\n",
       "      <td>1622</td>\n",
       "      <td>21.978320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Split  Samples  Percentage\n",
       "0       Train     5182   70.216802\n",
       "1  Validation      576    7.804878\n",
       "2        Test     1622   21.978320"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Distribution (Counts)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ang</th>\n",
       "      <td>840</td>\n",
       "      <td>93</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fru</th>\n",
       "      <td>1321</td>\n",
       "      <td>147</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hap</th>\n",
       "      <td>1075</td>\n",
       "      <td>119</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neu</th>\n",
       "      <td>1191</td>\n",
       "      <td>133</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>755</td>\n",
       "      <td>84</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train  Validation  Test\n",
       "emotion                         \n",
       "ang        840          93   170\n",
       "fru       1321         147   381\n",
       "hap       1075         119   442\n",
       "neu       1191         133   384\n",
       "sad        755          84   245"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_stats = pd.DataFrame({\n",
    "    \"Split\": [\"Train\", \"Validation\", \"Test\"],\n",
    "    \"Samples\": [len(train_df), len(val_df), len(test_df)],\n",
    "    \"Percentage\": [\n",
    "        len(train_df) / len(df_filtered_merge) * 100,\n",
    "        len(val_df) / len(df_filtered_merge) * 100,\n",
    "        len(test_df) / len(df_filtered_merge) * 100\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Split Summary\")\n",
    "display(split_stats)\n",
    "\n",
    "emotion_distribution = pd.DataFrame({\n",
    "    \"Train\": train_df['emotion'].value_counts(),\n",
    "    \"Validation\": val_df['emotion'].value_counts(),\n",
    "    \"Test\": test_df['emotion'].value_counts()\n",
    "}).fillna(0).astype(int)\n",
    "\n",
    "print(\"Emotion Distribution (Counts)\")\n",
    "display(emotion_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['session', 'method', 'gender', 'emotion', 'n_annotators', 'agreement',\n",
       "       'path', 'audio_path'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>method</th>\n",
       "      <th>gender</th>\n",
       "      <th>emotion</th>\n",
       "      <th>n_annotators</th>\n",
       "      <th>agreement</th>\n",
       "      <th>path</th>\n",
       "      <th>audio_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5854</th>\n",
       "      <td>4</td>\n",
       "      <td>script</td>\n",
       "      <td>M</td>\n",
       "      <td>neu</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Session4/sentences/wav/Ses04M_script01_1/Ses04...</td>\n",
       "      <td>/Users/vanilla/.cache/kagglehub/datasets/samue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7732</th>\n",
       "      <td>4</td>\n",
       "      <td>impro</td>\n",
       "      <td>M</td>\n",
       "      <td>fru</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Session4/sentences/wav/Ses04M_impro02/Ses04M_i...</td>\n",
       "      <td>/Users/vanilla/.cache/kagglehub/datasets/samue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>2</td>\n",
       "      <td>impro</td>\n",
       "      <td>F</td>\n",
       "      <td>hap</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Session2/sentences/wav/Ses02F_impro03/Ses02F_i...</td>\n",
       "      <td>/Users/vanilla/.cache/kagglehub/datasets/samue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2853</th>\n",
       "      <td>2</td>\n",
       "      <td>impro</td>\n",
       "      <td>F</td>\n",
       "      <td>neu</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Session2/sentences/wav/Ses02F_impro03/Ses02F_i...</td>\n",
       "      <td>/Users/vanilla/.cache/kagglehub/datasets/samue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>1</td>\n",
       "      <td>script</td>\n",
       "      <td>F</td>\n",
       "      <td>fru</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Session1/sentences/wav/Ses01F_script01_1/Ses01...</td>\n",
       "      <td>/Users/vanilla/.cache/kagglehub/datasets/samue...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      session  method gender emotion  n_annotators  agreement  \\\n",
       "5854        4  script      M     neu             3          2   \n",
       "7732        4   impro      M     fru             3          3   \n",
       "2836        2   impro      F     hap             4          2   \n",
       "2853        2   impro      F     neu             3          2   \n",
       "1090        1  script      F     fru             3          2   \n",
       "\n",
       "                                                   path  \\\n",
       "5854  Session4/sentences/wav/Ses04M_script01_1/Ses04...   \n",
       "7732  Session4/sentences/wav/Ses04M_impro02/Ses04M_i...   \n",
       "2836  Session2/sentences/wav/Ses02F_impro03/Ses02F_i...   \n",
       "2853  Session2/sentences/wav/Ses02F_impro03/Ses02F_i...   \n",
       "1090  Session1/sentences/wav/Ses01F_script01_1/Ses01...   \n",
       "\n",
       "                                             audio_path  \n",
       "5854  /Users/vanilla/.cache/kagglehub/datasets/samue...  \n",
       "7732  /Users/vanilla/.cache/kagglehub/datasets/samue...  \n",
       "2836  /Users/vanilla/.cache/kagglehub/datasets/samue...  \n",
       "2853  /Users/vanilla/.cache/kagglehub/datasets/samue...  \n",
       "1090  /Users/vanilla/.cache/kagglehub/datasets/samue...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Stats\n",
    "\n",
    "*(We still didnt recieve the audio files from the source, the data on HF has everything but the audio files)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_stats(df_subset, sample_size=100):\n",
    "    \"\"\"Get audio duration statistics from a sample\"\"\"\n",
    "    durations = []\n",
    "    sample = df_subset.sample(min(sample_size, len(df_subset)), random_state=42)\n",
    "    \n",
    "    for _, row in tqdm(sample.iterrows(), total=len(sample), desc=\"Analyzing audio\"):\n",
    "        try:\n",
    "            waveform, sr = torchaudio.load(row['audio_path'])\n",
    "            duration = waveform.shape[1] / sr\n",
    "            durations.append(duration)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {row['audio_path']}: {e}\")\n",
    "    \n",
    "    return np.array(durations)\n",
    "\n",
    "print(\"Analyzing audio durations (sampling 100 files)...\")\n",
    "durations = get_audio_stats(train_df, sample_size=100)\n",
    "\n",
    "print(f\"Audio Duration Statistics:\")\n",
    "print(f\"Mean: {durations.mean():.2f}s\")\n",
    "print(f\"Std:  {durations.std():.2f}s\")\n",
    "print(f\"Min:  {durations.min():.2f}s\")\n",
    "print(f\"Max:  {durations.max():.2f}s\")\n",
    "print(f\"Median: {np.median(durations):.2f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
